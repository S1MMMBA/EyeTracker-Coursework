\documentclass[14pt, a4paper]{extarticle}
\usepackage[T2A]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[english, russian]{babel}
\usepackage{fontspec}
\setmainfont{Times New Roman}

\usepackage[top=20mm, bottom=20mm, left=30mm, right=10mm]{geometry}
\usepackage{setspace}
\onehalfspacing

\usepackage{titlesec}
\usepackage{titletoc}
\usepackage[hidelinks]{hyperref}

\titleformat{\section}
{\normalfont\bfseries\centering\MakeUppercase}
{}
{0pt}
{}
\titlespacing{\section}{0pt}{*4}{*2}

\titleformat{\subsection}
{\normalfont\bfseries\large}
{}
{0pt}
{}
\titlespacing{\subsection}{\parindent}{*4}{*2}

\titleformat{\subsubsection}
{\normalfont\bfseries}
{}
{0pt}
{}
\titlespacing{\subsubsection}{\parindent}{*4}{*2}

\usepackage{graphicx}
\graphicspath{{images/}}

\usepackage{enumitem}
\setlist{nosep, leftmargin=*}

\usepackage{tabularx}
\usepackage{booktabs}
\usepackage{caption}
\captionsetup[table]{justification=raggedright, singlelinecheck=false, font=small, labelfont=bf}
\captionsetup[figure]{justification=centering, font=small, labelfont=bf}

\usepackage{listings}
\usepackage{xcolor}
\lstset{
    basicstyle=\ttfamily\small,
    breaklines=true,
    frame=single,
    numbers=left,
    numberstyle=\tiny\color{gray},
    tabsize=4,
    inputencoding=utf8,
    extendedchars=true
}

\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\fancyfoot[C]{\thepage}
\renewcommand{\headrulewidth}{0pt}

\newcommand{\maketitlepage}{
    \begin{titlepage}
        \centering
        
        % Верхняя часть титульного листа
        \vspace*{-1cm}
        \textbf{МИНИСТЕРСТВО ОБРАЗОВАНИЯ РЕСПУБЛИКИ БЕЛАРУСЬ}\\[1cm]
        \textbf{БЕЛОРУССКИЙ ГОСУДАРСТВЕННЫЙ УНИВЕРСИТЕТ}\\[0.5cm]
        \textbf{ФАКУЛЬТЕТ ПРИКЛАДНОЙ МАТЕМАТИКИ И ИНФОРМАТИКИ}\\[0.5cm]
        \textbf{Кафедра математического моделирования и анализа данных}\\[2cm]
        
        % ФИО исполнителя по центру над темой
        \textbf{Сазончик Иван Михайлович}\\[0.5cm]
        
        % Название темы
        {\Large \textbf{ОЦЕНКА КАЧЕСТВА ЭНТРОПИИ В БИОЛОГИЧЕСКИХ ГЕНЕРАТОРАХ СЛУЧАЙНЫХ ЧИСЕЛ НА ОСНОВЕ ПОВЕДЕНЧЕСКИХ ФАКТОРОВ}}\\[2cm]
        
        % Курс и группа по центру под темой
        \text{Курсовая работа}\\[0.3cm]
        студента 4 курса 9 группы\\[0.1cm]
        
        % Правая часть - научный руководитель
        \begin{flushright}
            \textbf{Научный руководитель:}\\
            старший преподаватель\\
            М.А. Казловский\\[0.5cm]
        \end{flushright}
        % Нижняя часть титульного листа
        \vfill
        \textbf{Минск, 2025}
    \end{titlepage}
}

\begin{document}

\maketitlepage

\newpage
\renewcommand{\contentsname}{ОГЛАВЛЕНИЕ}
\tableofcontents

\newpage
\section*{ВВЕДЕНИЕ}
\addcontentsline{toc}{section}{ВВЕДЕНИЕ}

В современных условиях цифровой трансформации и повсеместного внедрения криптографических систем надёжная генерация случайных чисел является фундаментальной задачей информационной безопасности. Случайные числа и ключевые последовательности используются в широком спектре приложений: от шифрования данных и цифровых подписей до протоколов аутентификации и лотерейных систем. Качество таких последовательностей напрямую определяет устойчивость криптосистем к атакам.

Традиционные генераторы случайных чисел (ГСЧ) можно разделить на три основных класса: алгоритмические (псевдослучайные), физические (аппаратные) и комбинированные. Алгоритмические ГСЧ, хотя и обладают высокой скоростью и воспроизводимостью, по своей природе детерминированы и уязвимы при компрометации начального состояния (seed). Физические ГСЧ, основанные на измерениях шумовых процессов (тепловой шум, радиоактивный распад и др.), обеспечивают истинную случайность, но часто требуют специализированного и дорогостоящего оборудования, а их выход может быть подвержен нестабильности и внешним помехам. Всё это актуализирует поиск новых, доступных, недетерминированных и устойчивых источников энтропии, интегрируемых в повседневные вычислительные среды.

Перспективным направлением в этой области является использование биометрических данных человека. Биометрия, изучающая уникальные физиологические и поведенческие характеристики индивидов, предлагает два основных типа источников энтропии. К \textit{физиологическим} относятся относительно стабильные во времени, но сложные для непрерывного измерения параметры, такие как ритмы сердца (ЭКГ), мозговые волны (ЭЭГ), характеристика кровотока. \textit{Поведенческие} факторы, напротив, отражают динамические и зачастую непредсказуемые паттерны деятельности человека: динамика нажатий клавиш, движения компьютерной мыши, жесты, речь и, что особенно интересно, саккадические и прослеживающие движения глаз.

Движения глаз представляют собой непрерывный, высокочастотный и в значительной степени непроизвольный процесс, управляемый сложным взаимодействием когнитивных, перцептивных и нейромоторных систем. Траектория взгляда даже при фиксации на статичном объекте демонстрирует микродвижения (тремор, дрейф, микросаккады), которые являются принципиально непредсказуемыми на длительных интервалах и потенциально богатым источником энтропии. Использование этого биометрического канала не требует инвазивного или дорогого оборудования --- достаточно стандартной веб-камеры и алгоритмов компьютерного зрения, что открывает возможности для создания программных биологических ГСЧ (BioRNG) массового применения.

\textbf{Целью данной работы} является разработка, программная реализация и комплексная оценка качества биологического генератора случайных чисел, основанного на анализе поведенческого фактора --- траектории движения глаз человека.

Для достижения поставленной цели в ходе исследования были последовательно решены следующие \textbf{задачи}:
\begin{enumerate}
    \item Разработка программного комплекса для захвата видеопотока с веб-камеры, трекинга лицевых ориентиров и выделения параметров движения глаз (координаты взгляда, скорость, направление, состояние век) в реальном времени.
    \item Реализация алгоритма извлечения и накопления энтропии из потока поведенческих данных, включающего этапы фильтрации (исключение кадров с закрытыми глазами, подавление шума), квантования извлечённых параметров и формирования битовой последовательности.
    \item Оценка статистического качества и непредсказуемости генерируемых битовых последовательностей с использованием набора стандартизированных тестов NIST SP 800-90B, предназначенных для оценки источников энтропии.
    \item Экспериментальное исследование влияния контекста деятельности пользователя (произвольные движения глаз, серфинг в интернете, просмотр видео) на количественные и качественные характеристики извлекаемой энтропии.
\end{enumerate}

\textbf{Объектом исследования} выступает энтропия, извлекаемая из траектории движения глаз человека как динамического поведенческого биометрического сигнала.

\textbf{Предметом исследования} являются алгоритмы и методы извлечения, обработки и статистической оценки энтропии из данных трекинга взгляда.

В работе применяется комплекс \textbf{методов исследования}:
\begin{itemize}
    \item Методы \textit{компьютерного зрения} и машинного обучения (библиотеки MediaPipe, OpenCV) для детекции лица, локализации ключевых точек глаз и отслеживания их перемещений.
    \item Методы \textit{цифровой обработки сигналов} и \textit{статистического анализа} для фильтрации данных, выделения признаков и первичной оценки их стохастических свойств.
    \item Стандартизированные методы \textit{тестирования энтропии} (NIST SP 800-90B), включая оценку минимальной энтропии, тесты на независимость и идентичность распределения (IID), а также тесты для не-IID данных.
    \item Метод \textit{экспериментального исследования} для сбора данных в различных сценариях и сравнительного анализа результатов.
\end{itemize}

Практическая значимость работы заключается в демонстрации возможности построения доступного программного ГСЧ с истинной энтропией, использующего стандартные аппаратные средства. Теоретическая ценность состоит в исследовании свойств энтропии, порождаемой сложной биологической системой (окуломоторной), и влияния на эти свойства внешнего когнитивного контекста.

\newpage
\section{ТЕОРЕТИЧЕСКИЕ ОСНОВЫ БИОЛОГИЧЕСКИХ ГЕНЕРАТОРОВ СЛУЧАЙНЫХ ЧИСЕЛ}

\subsection{Классификация источников энтропии}

В современной криптографии генераторы случайных чисел (ГСЧ) классифицируются по источнику энтропии, которая служит основой для формирования недетерминированных последовательностей. Все источники энтропии можно разделить на три основные категории: алгоритмические (псевдослучайные), физические и биометрические.

\textbf{Алгоритмические ГСЧ} (Pseudorandom Number Generators, PRNG) используют детерминированные математические алгоритмы для преобразования начального значения (seed) в последовательность чисел, которая обладает статистическими свойствами случайности. К преимуществам PRNG относятся высокая скорость генерации, воспроизводимость и простота программной реализации. Однако их фундаментальным недостатком является детерминированность --- при одинаковом начальном значении генерируется идентичная последовательность, что делает их уязвимыми к атакам, если seed становится известным злоумышленнику.

\textbf{Физические ГСЧ} (True Random Number Generators, TRNG) основаны на измерении фундаментальных физических процессов, которые по своей природе являются стохастическими и недетерминированными. К таким процессам относятся:
\begin{itemize}
    \item Тепловой шум в резисторах (Johnson--Nyquist noise)
    \item Шум в полупроводниковых приборах (диоды, транзисторы)
    \item Радиоактивный распад
    \item Квантовые явления (фотонная статистика, квантовая запутанность)
    \item Атмосферный шум
\end{itemize}

Физические ГСЧ обеспечивают истинную случайность и являются «золотым стандартом» для криптографических приложений. Однако они имеют существенные ограничения: требуют специализированного аппаратного обеспечения, могут быть чувствительны к температурным колебаниям и электромагнитным помехам, а скорость генерации часто ограничена характеристиками физического процесса.

\textbf{Биометрические ГСЧ} представляют собой особый класс генераторов, использующих в качестве источника энтропии уникальные характеристики живых организмов, преимущественно человека. В отличие от физических ГСЧ, биометрические источники не требуют специализированного аппаратного обеспечения --- многие из них могут быть реализованы с использованием стандартных периферийных устройств. Биометрические ГСЧ можно разделить на две подкатегории:

\begin{enumerate}
    \item \textit{Физиологические источники} --- основаны на измерении параметров биологических систем организма:
    \begin{itemize}
        \item Электрокардиограмма (ЭКГ) --- электрическая активность сердца
        \item Электроэнцефалограмма (ЭЭГ) --- электрическая активность мозга
        \item Фотоплетизмограмма (ФПГ) --- изменения кровенаполнения сосудов
        \item Электромиограмма (ЭМГ) --- электрическая активность мышц
        \item Дерматоглифические узоры (отпечатки пальцев)
    \end{itemize}
    
    \item \textit{Поведенческие источники} --- основаны на анализе паттернов деятельности человека:
    \begin{itemize}
        \item Движения глаз (окуломоторная активность) --- саккады, фиксации, плавные следящие движения
        \item Динамика работы с клавиатурой (keystroke dynamics) --- временные интервалы между нажатиями, сила нажатия
        \item Движения компьютерной мыши --- траектория, скорость, ускорение, клики
        \item Особенности почерка (динамическая биометрия)
        \item Паттерны голоса и речи
    \end{itemize}
\end{enumerate}

Биометрические ГСЧ обладают уникальным преимуществом --- они используют энтропию, порождаемую сложными биологическими системы, которая по своей природе является недетерминированной и трудно предсказуемой. Однако они также имеют специфические вызовы, такие как зависимость от состояния субъекта, необходимость фильтрации артефактов и этические вопросы, связанные с использованием биометрических данных.

\subsection{Особенности поведенческих источников энтропии}

Поведенческие источники энтропии, в отличие от физиологических, характеризуются высокой динамичностью и непосредственной связью с когнитивными процессами. Это определяет их специфические особенности, которые необходимо учитывать при разработке биологических ГСЧ.

\textbf{Непредсказуемость микро-движений}. Даже при выполнении, казалось бы, простых и повторяемых задач, поведенческие паттерны человека демонстрируют существенную вариабельность на микроуровне. Например:
\begin{itemize}
    \item При фиксации взгляда на неподвижном объекте глаза совершают непроизвольные микродвижения трех типов: \textit{тремор} (высокочастотные колебания с амплитудой 20-40 угловых секунд), \textit{дрейф} (медленные смещения) и \textit{микросаккады} (быстрые корректирующие движения)
    \item При печати на клавиатуре интервалы между нажатиями одних и тех же клавишых комбинаций варьируются в пределах 20-100 мс даже у опытных машинисток
    \item Траектория движения мыши при выполнении однотипных задач (например, клик по кнопке) никогда не повторяется точно из-за мышечной усталости, дрожания руки и неосознанных корректировок
\end{itemize}

Эта микро-вариабельность обусловлена сложностью нейромоторной системы человека, которая включает множество источников шума: стохастичность высвобождения нейромедиаторов, вариабельность проведения нервных импульсов, нелинейность мышечного ответа. Эти физиологические шумы делают поведенческие паттерны принципиально непредсказуемыми на достаточно длительных интервалах.

\textbf{Влияние когнитивных процессов}. Поведенческие паттерны тесно связаны с текущим когнитивным состоянием человека, что создает как возможности, так и вызовы для генерации энтропии:
\begin{itemize}
    \item \textit{Внимание и концентрация} --- уровень внимания влияет на стабильность движений. При высокой концентрации движения становятся более точными, но при этом могут уменьшаться случайные колебания, что потенциально снижает энтропию
    \item \textit{Усталость и стресс} --- физическая и умственная усталость увеличивает вариабельность движений, но также может вносить систематические смещения (например, замедление реакции)
    \item \textit{Эмоциональное состояние} --- эмоции влияют на двигательную активность: тревожность может увеличивать частоту микродвижений, тогда как спокойное состояние --- уменьшать
    \item \textit{Когнитивная нагрузка} --- выполнение параллельных задач (мультитаскинг) существенно изменяет поведенческие паттерны, часто увеличивая их непредсказуемость
\end{itemize}

\textbf{Контекстуальная зависимость}. Качество и количество энтропии, извлекаемой из поведенческих источников, существенно зависит от контекста деятельности:
\begin{itemize}
    \item \textit{Произвольная активность} --- когда пользователь сознательно пытается генерировать «случайные» движения, возникает парадоксальный эффект: сознательный контроль снижает истинную случайность, так как человек склонен к созданию паттернов и избеганию «крайних» значений
    \item \textit{Естественная деятельность} --- при выполнении осмысленных задач (чтение, серфинг в интернете, просмотр видео) движения носят более естественный характер и могут предоставлять более качественную энтропию, так как когнитивные процессы фокусируются на содержании задачи, а не на контроле движений
    \item \textit{Тип задачи} --- разные виды деятельности генерируют энтропию с различными характеристиками. Например, чтение текста порождает регулярные саккадические движения с фиксациями, тогда как свободное рассматривание изображений создает более хаотичную траекторию взгляда
\end{itemize}

\textbf{Технические особенности измерения}. Поведенческие источники требуют специальных подходов к измерению и обработке сигналов:
\begin{itemize}
    \item \textit{Дискретизация и квантование} --- аналоговые поведенческие сигналы (координаты взгляда, временные метки) должны быть преобразованы в цифровую форма, что вносит дополнительный шум квантования
    \item \textit{Артефакты измерений} --- аппаратные ограничения (частота кадров камеры, разрешение сенсоров) и внешние факторы (освещение, помехи) могут искажать измеряемые параметры
    \item \textit{Предобработка сигналов} --- необходима фильтрация высокочастотного шума, устранение выбросов и компенсация систематических ошибок измерений
\end{itemize}

Поведенческие источники энтропии, и особенно движения глаз, представляют особый интерес для создания биологических ГСЧ. Окуломоторная система сочетает в себе высокую частоту обновления (до 1000 Гц в специализированных системах), богатство непредсказуемых микро-движений и относительно простую техническую реализацию измерения с использованием обычных веб-камер. Эти особенности делают движения глаз перспективным кандидатом для создания доступных, но криптографически стойких источников случайности.

\newpage
\section{РАЗРАБОТКА ПРОГРАММНОГО КОМПЛЕКСА ДЛЯ СБОРА ЭНТРОПИИ ДВИЖЕНИЙ ГЛАЗ}

\subsection{Общий вид интерфейса программного комплекса}

Интерфейс программного комплекса реализован в виде окна видеопотока с веб-камеры, на которое в реальном времени накладываются элементы визуализации работы системы. В центральной части окна отображается изображение пользователя, получаемое с камеры, а также ключевые точки области глаз, используемые для анализа направления взгляда.

В процессе работы системы на изображении визуализируется текущая точка взгляда, а также отображается информация о наличии или отсутствии движения глаз. При обнаружении значимого движения система фиксирует соответствующее событие и использует его параметры для извлечения энтропии.

В левой верхней части интерфейса выводится служебная информация, включающая текущий статус системы, количество зафиксированных движений, число статичных кадров подряд, состояние глаз (открыты или закрыты), а также оценка качества собранных данных. Данная информация позволяет оператору в реальном времени контролировать корректность работы алгоритмов и качество входных данных.

Разработанный интерфейс ориентирован на минимальное вмешательство пользователя в процесс работы системы и предназначен преимущественно для визуального контроля и отладки. Основной процесс сбора энтропии и генерации случайных битов происходит автоматически и не требует активных действий со стороны пользователя.

\subsection{Архитектура системы}

Программный комплекс для сбора энтропии движений глаз был разработан с использованием модульного подхода, что обеспечивает гибкость, масштабируемость и возможность независимой модификации отдельных компонентов.

\textbf{Модуль трекинга взгляда (AdvancedGazeTracker)} является ядром системы и выполняет следующие функции:
\begin{itemize}
    \item Захват видеопотока с веб-камеры в реальном времени с частотой до 30 кадров в секунду
    \item Детекция лица и локализация 468 лицевых ориентиров с использованием нейросетевой модели MediaPipe Face Mesh
    \item Выделение 16 ключевых точек для каждого глаза с последующим вычислением центра глаза
    \item Определение состояния век (открыты/закрыты) на основе отношения вертикального и горизонтального расстояний между ключевыми точками
    \item Расчет координат точки взгляда на экране с комбинированием методов центров глаз и смещения зрачков
    \item Детекция значимых движений глаз с применением пороговой фильтрации по величине и временным интервалам
    \item Визуализация результатов трекинга с наложением графических элементов на видеопоток
\end{itemize}

\textbf{Модуль извлечения энтропии (MovementBasedCryptoGenerator)} реализует криптографическую обработку данных:
\begin{itemize}
    \item Прием потока данных о движениях глаз от модуля трекинга
    \item Извлечение энтропии из 6 независимых источников: координат X и Y, величины движения, направления, временных меток и физиологических параметров
    \item Квантование аналоговых значений в битовые последовательности с использованием младших битов для увеличения случайности
    \item Формирование пула энтропии с ограниченной емкостью (1000 элементов) по принципу FIFO (First-In-First-Out)
    \item Генерация криптографических ключей заданной длины (128 или 256 бит) с автоматическим дополнением при недостатке энтропии
\end{itemize}

\textbf{Модуль оценки и сохранения данных} обеспечивает персистентность и анализ:
\begin{itemize}
    \item Логирование всех событий движения в структурированном формате JSON с временными метками
    \item Сохранение сырых битовых последовательностей в бинарные файлы для последующего статистического анализа
    \item Реализация интерактивного интерфейса управления с обработкой клавиатурных команд
    \item Расчет статистических показателей в реальном времени: количество движений, процент движения, качество данных
    \item Экспорт сгенерированных ключей в файлы формата .bin и .txt для использования в криптографических приложениях
\end{itemize}

Взаимодействие между модулями осуществляется через четко определенные программные интерфейсы. Модуль трекинга передает объекты данных, содержащие координаты взгляда, параметры движения и метаданные, в модуль извлечения энтропии. Последний аккумулирует данные до достижения порогового значения, после чего инициирует процедуру генерации ключа. Модуль оценки работает асинхронно, сохраняя данные на диск и обновляя статистику без блокировки основных процессов.

\subsection{Алгоритмы трекинга}

\subsubsection{Использование MediaPipe Face Mesh для детекции лицевых ориентиров}

Для детекции лицевых ориентиров была выбрана нейросетевая модель MediaPipe Face Mesh, разработанная компанией Google. Эта модель обеспечивает баланс между точностью и производительностью, что критически важно для работы в реальном времени. Модель детектирует 468 трехмерных точек на лице с точностью локализации до 1-2 пикселей при разрешении кадра 640×480.

Инициализация модели осуществляется со следующими параметрами:
\begin{itemize}
    \item \texttt{max\_num\_faces=1} --- ограничение на одно лицо в кадре для увеличения производительности
    \item \texttt{refine\_landmarks=True} --- уточнение ключевых точек глаз и губ для повышения точности
    \item \texttt{min\_detection\_confidence=0.8} --- порог уверенности детекции, фильтрующий ложные срабатывания
    \item \texttt{min\_tracking\_confidence=0.8} --- порог уверенности отслеживания между кадрами
    \item \texttt{static\_image\_mode=False} --- оптимизация для видеопотока с сохранением состояния между кадрами
\end{itemize}

Для каждого кадра выполняется следующий конвейер обработки:
\begin{enumerate}
    \item Преобразование кадра из формата BGR (OpenCV) в RGB (MediaPipe)
    \item Передача кадра в модель Face Mesh и получение массива нормализованных координат (от 0 до 1)
    \item Выделение подмножества точек, соответствующих глазам: 16 точек для левого глаза (индексы 33, 7, 163, 144, 145, 153, 154, 155, 133, 173, 157, 158, 159, 160, 161, 246) и 16 точек для правого глаза (индексы 362, 382, 381, 380, 374, 373, 390, 249, 263, 466, 388, 387, 386, 385, 384, 398)
    \item Масштабирование нормализованных координат до абсолютных значений в пикселях с учетом разрешения кадра
\end{enumerate}

\subsubsection{Определение открытости глаз и фильтрация невалидных кадров}

Для обеспечения качества данных критически важна фильтрация кадров с закрытыми глазами, которые не содержат полезной энтропии. Алгоритм определения открытости глаз основан на расчете отношения вертикального и горизонтального размеров глазной щели.

Для каждого глаза вычисляются две метрики:
\begin{itemize}
    \item \textbf{Вертикальное расстояние} между верхней и нижней точками века:
    $$d_v^{left} = |y_{159} - y_{145}|, \quad d_v^{right} = |y_{386} - y_{374}|$$
    где $y_{159}$ и $y_{145}$ --- y-координаты верхней и нижней точек левого века, $y_{386}$ и $y_{374}$ --- аналогичные точки правого глаза.
    
    \item \textbf{Горизонтальное расстояние} между внешним и внутренним углами глаза:
    $$d_h^{left} = |x_{33} - x_{133}|, \quad d_h^{right} = |x_{362} - x_{263}|$$
\end{itemize}

Отношение открытости вычисляется по формуле:
$$O_{eye} = \min\left(1.0, \frac{d_v}{d_h} \times 2.0\right)$$

Порог открытости установлен на уровне 0.4. Глаз считается открытым, если $O_{eye} > 0.4$. Для дополнительной проверки вычисляется симметрия между глазами:
$$S = 1.0 - |O_{left} - O_{right}|$$

Кадр считается валидным только если:
\begin{enumerate}
    \item Оба глаза открыты ($O_{left} > 0.4$ и $O_{right} > 0.4$)
    \item Симметрия между глазами превышает 0.85 ($S > 0.85$)
    \item Разница в открытости не превышает 0.15 ($|O_{left} - O_{right}| < 0.15$)
\end{enumerate}

Эти критерии позволяют отфильтровывать кадры с морганием, прищуриванием и асимметричным закрытием глаз, которые могут вносить систематические ошибки в измерения.

\subsubsection{Детекция значимых движений взгляда}

Детекция движений осуществляется по принципу сравнения текущей позиции взгляда с предыдущей значимой позицией. Алгоритм включает несколько этапов фильтрации для исключения микродвижений и дрейфа:

\textbf{1. Вычисление положения взгляда:}
Позиция взгляда вычисляется комбинированным методом:
\begin{itemize}
    \item \textbf{Метод центров глаз:} вычисляется среднее арифметическое центров левого и правого глаза
    $$C_x = \frac{x_{left\_center} + x_{right\_center}}{2}, \quad C_y = \frac{y_{left\_center} + y_{right\_center}}{2}$$
    
    \item \textbf{Метод смещения зрачков:} оценивается смещение радужки относительно центра глаза
    $$\Delta_x = \frac{(x_{468} - x_{left\_center}) + (x_{473} - x_{right\_center})}{2}$$
    $$\Delta_y = \frac{(y_{468} - y_{left\_center}) + (y_{473} - y_{right\_center})}{2}$$
    
    \item \textbf{Комбинированная оценка:} итоговые координаты с весовыми коэффициентами
    $$G_x = C_x + 0.3 \times \Delta_x, \quad G_y = C_y + 0.3 \times \Delta_y$$
\end{itemize}

\textbf{2. Расчет параметров движения:}
Для каждой новой позиции взгляда вычисляются:
\begin{itemize}
    \item \textbf{Величина движения:} евклидово расстояние от предыдущей значимой позиции
    $$M = \sqrt{(G_x^{current} - G_x^{previous})^2 + (G_y^{current} - G_y^{previous})^2}$$
    
    \item \textbf{Направление движения:} угол в радианах относительно горизонтальной оси
    $$\theta = \operatorname{atan2}(G_y^{current} - G_y^{previous}, G_x^{current} - G_x^{previous})$$
\end{itemize}

\textbf{3. Пороговая фильтрация:}
Движение считается значимым и регистрируется в системе, если выполняются условия:
\begin{itemize}
    \item Величина движения превышает порог $M > 15$ пикселей (настроечный параметр)
    \item Время с последнего зарегистрированного движения превышает минимальный интервал $\Delta t > 0.05$ секунды
    \item Глаза открыты (проверка по алгоритму из предыдущего раздела)
\end{itemize}

Порог в 15 пикселей был определен эмпирически в ходе предварительных экспериментов как оптимальный баланс между чувствительностью (регистрация настоящих движений) и специфичностью (игнорирование шума и микродвижений).

\subsection{Алгоритм извлечения энтропии}

\subsubsection{Источники энтропии}

Система извлекает энтропию из шести независимых источников, каждый из которых вносит свой вклад в общую случайность генерируемой последовательности:

\textbf{1. Пространственные координаты (X, Y):}
\begin{itemize}
    \item \textit{Физический источник:} абсолютные координаты точки взгляда на экране
    \item \textit{Разрядность:} 32-битные числа с плавающей запятой
    \item \textit{Извлекаемые биты:} 4 младших бита из каждого байта координаты после умножения на 1000 и приведения к целому типу
    \item \textit{Обоснование:} младшие биты координат наиболее чувствительны к микродвижениям и шуму измерений
\end{itemize}

\textbf{2. Величина движения:}
\begin{itemize}
    \item \textit{Физический источник:} евклидово расстояние между последовательными позициями взгляда
    \item \textit{Разрядность:} 32-битное число с плавающей запятой
    \item \textit{Извлекаемые биты:} 4 младших бита после умножения на 100 и приведения к целому типу
    \item \textit{Обоснование:} величина движения отражает амплитуду саккад, которая варьируется непредсказуемо
\end{itemize}

\textbf{3. Направление движения:}
\begin{itemize}
    \item \textit{Физический источник:} угол движения в радианах (от $-\pi$ до $\pi$)
    \item \textit{Преобразование:} квантование в 8 секторов: $\theta_{quantized} = \left\lfloor \frac{\theta + \pi}{2\pi} \times 8 \right\rfloor$
    \item \textit{Извлекаемые биты:} 3 бита, представляющие номер сектора
    \item \textit{Обоснование:} направление саккад зависит от визуальных стимулов и когнитивных процессов
\end{itemize}

\textbf{4. Временные метки:}
\begin{itemize}
    \item \textit{Физический источник:} системное время в микросекундах
    \item \textit{Извлекаемые биты:} 4 младших бита микросекундной части времени
    $$\text{bits} = \text{format}((\text{timestamp} - \lfloor \text{timestamp} \rfloor) \times 10^6 \mod 16, '04b')$$
    \item \textit{Обоснование:} задержки в нейромоторной системе создают случайные вариации временных интервалов
\end{itemize}

\textbf{5. Физиологические параметры:}
\begin{itemize}
    \item \textbf{Открытость глаз:} среднее значение открытости левого и правого глаза
    $$\text{bits}_{openness} = \text{format}(\lfloor O_{avg} \times 100 \rfloor \mod 8, '03b')$$
    
    \item \textbf{Уровень внимания:} комплексный показатель, вычисляемый как взвешенная сумма:
    $$A = 0.4 \times O_{avg} + 0.3 \times S + 0.3 \times (1 - \min(1.0, \frac{F_{still}}{50}))$$
    где $S$ --- симметрия открытости, $F_{still}$ --- количество последовательных статичных кадров
    $$\text{bits}_{attention} = \text{format}(\lfloor A \times 100 \rfloor \mod 8, '03b')$$
\end{itemize}

\subsubsection{Квантование и бит-экстракция}

Процесс преобразования аналоговых значений в битовую последовательность включает три этапа:

\textbf{1. Предобработка и нормализация:}
\begin{itemize}
    \item Масштабирование значений в заданные диапазоны
    \item Фильтрация выбросов с использованием скользящего медианного фильтра
    \item Вычитание тренда для устранения медленных дрейфов
\end{itemize}

\textbf{2. Квантование:}
\begin{itemize}
    \item Преобразование непрерывных значений в дискретные уровни
    \item Использование нелинейного квантования для областей с высокой плотностью вероятности
    \item Для координат: $Q(x) = \lfloor x \times 1000 \rfloor \mod 256$
    \item Для величин: $Q(m) = \lfloor m \times 100 \rfloor \mod 16$
\end{itemize}

\textbf{3. Бит-экстракция:}
\begin{itemize}
    \item Извлечение младших битов из квантованных значений
    \item Для каждого параметра извлекается фиксированное количество бит согласно таблице 2.1
    \item Конкатенация битов из всех источников в единый поток
\end{itemize}

\begin{table}[ht]
\centering
\caption{Параметры извлечения энтропии из различных источников}
\label{tab:entropy_sources}
\resizebox{\textwidth}{!}{%
\begin{tabular}{|l|c|c|c|}
\hline
\textbf{Источник энтропии} & \textbf{Извлекаемые биты} & \textbf{Общий вклад} & \textbf{Частота обновления} \\ \hline
Координата X & 4 бита & 16.7\% & 30 Гц \\ \hline
Координата Y & 4 бита & 16.7\% & 30 Гц \\ \hline
Величина движения & 4 бита & 16.7\% & 1--10 Гц \\ \hline
Направление движения & 3 бита & 12.5\% & 1--10 Гц \\ \hline
Временная метка & 4 бита & 16.7\% & 30 Гц \\ \hline
Открытость глаз & 3 бита & 12.5\% & 30 Гц \\ \hline
Уровень внимания & 2 бита & 8.3\% & 30 Гц \\ \hline
\textbf{Итого} & \textbf{24 бита} & \textbf{100\%} & \textbf{30 Гц} \\ \hline
\end{tabular}%
}
\end{table}

\subsubsection{Формирование пула энтропии}

Для накопления и смешивания энтропии используется циклический буфер (очередь) фиксированного размера:

\textbf{Структура пула:}
\begin{itemize}
    \item \textit{Емкость:} 1000 элементов (регулируемый параметр)
    \item \textit{Организация:} кольцевой буфер (deque) с семантикой FIFO
    \item \textit{Тип элементов:} целые числа от 0 до 255 (байты)
\end{itemize}

\textbf{Алгоритм добавления:}
\begin{enumerate}
    \item Битовая последовательность разбивается на байты (по 8 бит)
    \item Каждый байт преобразуется в целое число
    \item Байт добавляется в конец очереди
    \item При переполнении самый старый байт удаляется из начала
\end{enumerate}

\textbf{Алгоритм извлечения:}
\begin{enumerate}
    \item Проверка достаточности энтропии: требуется не менее 20 событий движения
    \item Извлечение байтов из очереди в порядке добавления
    \item Применение функции сжатия для увеличения плотности энтропии
    \item Формирование ключа заданной длины (128 или 256 бит)
\end{enumerate}

\textbf{Функция сжатия:} Для увеличения качества энтропии применяется нелинейное преобразование:
$$C(x) = (x \oplus (x \ll 3) \oplus (x \gg 5)) \mod 256$$
где $\oplus$ --- побитовое XOR, $\ll$ и $\gg$ --- битовые сдвиги. Это преобразование устраняет линейные зависимости между последовательными байтами.

\subsection{Реализация}

\subsubsection{Язык Python и библиотеки}

Программный комплекс реализован на языке Python 3.8+, что обеспечивает кроссплатформенность, богатую экосистему библиотек и относительно простую разработку прототипов. Выбор конкретных библиотек обусловлен их функциональностью и производительностью:

\textbf{OpenCV (Open Source Computer Vision Library) версия 4.5+}: 
\begin{itemize}
    \item Захват видеопотока с веб-камеры через интерфейс VideoCapture
    \item Преобразование цветовых пространств (BGR ↔ RGB)
    \item Визуализация результатов трекинга с рисованием графических примитивов
    \item Обработка изображений в реальном времени с оптимизацией под многоядерные процессоры
\end{itemize}

\textbf{MediaPipe версия 0.8+}: 
\begin{itemize}
    \item Предобученная модель Face Mesh для детекции 468 лицевых ориентиров
    \item АПИ для работы с нейросетевыми моделями в реальном времени
    \item Оптимизация для CPU с использованием TFLite
    \item Поддержка рефайнинга ключевых точек для повышения точности
\end{itemize}

\textbf{NumPy версия 1.19+}: 
\begin{itemize}
    \item Векторизованные вычисления для обработки массивов ключевых точек
    \item Статистические функции для анализа данных
    \item Эффективное хранение и манипуляции с многомерными массивами
\end{itemize}

\textbf{Дополнительные библиотеки:}
\begin{itemize}
    \item \texttt{math} --- математические функции (atan2, sqrt)
    \item \texttt{time} --- работа с системным временем и задержками
    \item \texttt{json} --- сериализация данных для логирования
    \item \texttt{collections} --- структуры данных deque для эффективного управления историей
    \item \texttt{typing} --- аннотации типов для улучшения читаемости кода
\end{itemize}

\subsubsection{Логирование данных в бинарные файлы}

Для обеспечения воспроизводимости экспериментов и последующего анализа реализована система логирования данных в нескольких форматах:

\textbf{1. Бинарный формат (newbits\_data.bin):}
\begin{itemize}
    \item \textit{Назначение:} хранение сырых битовых последовательностей для тестирования энтропии
    \item \textit{Структура:} поток байтов без заголовков, каждый байт соответствует 8 битам энтропии
    \item \textit{Режим записи:} добавление в конец файла (append binary mode)
\end{itemize}

\textbf{3. Криптографические ключи (eye\_crypto\_key.bin, final\_eye\_key.bin):}
\begin{itemize}
    \item \textit{Назначение:} хранение сгенерированных ключей для использования в криптографических приложениях
    \item \textit{Структура:} сырые байты ключа заданной длины (16 байт для 128 бит, 32 байта для 256 бит)
    \item \textit{Дополнительно:} вывод HEX-представления в консоль для быстрой проверки
\end{itemize}
\newpage
\subsubsection{Интерфейс управления}

Интерактивный интерфейс управления реализован через обработку клавиатурных событий в окне OpenCV. Это позволяет пользователю контролировать процесс сбора данных и генерации ключей без остановки программы:

\textbf{Клавиша Q или ESC}: 
\begin{itemize}
    \item \textit{Действие:} корректное завершение программы
    \item \textit{Обработка:} выход из основного цикла, освобождение ресурсов камеры, закрытие окон
    \item \textit{Дополнительно:} автоматическая генерация финального ключа если накоплено более 50 движений
\end{itemize}

\textbf{Клавиша S (Statistics):}
\begin{itemize}
    \item \textit{Действие:} вывод текущей статистики в консоль
    \item \textit{Отображаемые метрики:} общее количество обработанных кадров, количество зарегистрированных движений, процент движения, качество данных, средняя величина движения
\end{itemize}

\textbf{Клавиша B (Bits):}
\begin{itemize}
    \item \textit{Действие:} генерация 128-битной случайной последовательности
    \item \textit{Процесс:} проверка достаточности энтропии, извлечение битов из пула, вычисление баланса, сохранение в файл
    \item \textit{Выходные данные:} статистика баланса и путь к сохраненному файлу
\end{itemize}

\textbf{Клавиша K (Key):}
\begin{itemize}
    \item \textit{Действие:} генерация 256-битного криптографического ключа
    \item \textit{Процесс:} проверка достаточности энтропии, извлечение 256 бит из пула, преобразование в байты, сохранение в бинарный файл
    \item \textit{Выходные данные:} размер ключа в байтах, HEX-префикс, статистика баланса
\end{itemize}

\textbf{Клавиша R (Reset):}
\begin{itemize}
    \item \textit{Действие:} сброс всех накопленных данных
    \item \textit{Очищаемые структуры:} история движений, история взгляда, история состояния глаз, счетчики статичных кадров и времени
    \item \textit{Применение:} позволяет начать новый сеанс сбора данных без перезапуска программы
\end{itemize}

\newpage
\section{МЕТОДОЛОГИЯ ОЦЕНКИ КАЧЕСТВА ЭНТРОПИИ}

\subsection{Тестовый стенд}

Для комплексной оценки качества энтропии, извлекаемой из движений глаз, был разработан специализированный тестовый стенд, позволяющий проводить измерения в различных сценариях активности пользователя. Целью создания тестового стенда являлось исследование влияния когнитивного состояния и типа деятельности на статистические характеристики генерируемой последовательности.

\textbf{Сценарии сбора данных:}
\begin{enumerate}
    \item \textbf{Случайные движения глазами:}
    \begin{itemize}
        \item \textit{Описание:} Пользователь произвольно перемещает взгляд по экрану без конкретной цели или визуальных стимулов.
        \item \textit{Цель:} Оценка максимального потенциала энтропии при осознанной попытке генерации случайных движений.
        \item \textit{Продолжительность:} 10 минут непрерывной активности.
    \end{itemize}
    
    \item \textbf{Серфинг в интернете:}
    \begin{itemize}
        \item \textit{Описание:} Естественная деятельность пользователя при просмотре веб-страниц, чтении статей, переходе по ссылкам.
        \item \textit{Цель:} Исследование качества энтропии в условиях реальной компьютерной деятельности.
        \item \textit{Продолжительность:} 15 минут работы с браузером.
    \end{itemize}
    
    \item \textbf{Просмотр фильма:}
    \begin{itemize}
        \item \textit{Описание:} Пользователь смотрит 10-минутный фрагмент динамичного фильма с активным сюжетом.
        \item \textit{Цель:} Анализ энтропии при пассивном восприятии визуального контента.
        \item \textit{Продолжительность:} 10 минут просмотра.
    \end{itemize}
\end{enumerate}
\newpage
\subsection{Инструменты оценки}

Для оценки качества энтропии использовался стандарт NIST SP 800-90B ``Recommendation for the Entropy Sources Used for Random Bit Generation''. Этот стандарт разработан Национальным институтом стандартов и технологий США (NIST) специально для тестирования источников энтропии, используемых в криптографических генераторах случайных чисел.

\textbf{Тестовый пакет NIST SP 800-90B включает две основные утилиты:}
\begin{itemize}
    \item \textbf{ea\_iid} (Entropy Assessment for IID data) --- для тестирования независимых и одинаково распределённых данных
    \item \textbf{ea\_non\_iid} (Entropy Assessment for non-IID data) --- для тестирования данных, которые могут не быть независимыми и одинаково распределёнными
\end{itemize}

\textbf{Основные проверяемые метрики:}
\begin{enumerate}
    \item \textbf{H\_original (энтропия на байт):} Мера неопределённости, содержащейся в одном байте последовательности
    $$H_{original} = -\sum_{i=0}^{255} p_i \log_2 p_i$$
    где $p_i$ --- вероятность появления байта со значением $i$
    
    \item \textbf{H\_bitstring (энтропия на бит):} Мера неопределённости, содержащейся в одном бите последовательности
    $$H_{bit} = -[p \log_2 p + (1-p) \log_2 (1-p)]$$
    где $p$ --- вероятность появления '1' в данной позиции
    
    \item \textbf{min(H\_original, 8 × H\_bitstring):} Консервативная оценка минимальной энтропии, используемая для non-IID данных
    $$H_{min} = \min(H_{original}, 8 \times H_{bitstring})$$
    
    \item \textbf{Хи-квадрат тест ($\chi^2$ test):} Проверка гипотезы о равномерном распределении байтов
    $$\chi^2 = \sum_{i=0}^{255} \frac{(O_i - E_i)^2}{E_i}$$
    где $O_i$ --- наблюдаемая частота, $E_i$ --- ожидаемая частота
    
    \item \textbf{Тест на самую длинную повторяющуюся подстроку:} Обнаружение повторяющихся паттернов в последовательности
    
    \item \textbf{Permutation tests:} Проверка гипотезы о независимости и одинаковом распределении (IID) данных
\end{enumerate}

\subsection{Критерии успешности}

Для признания биологического генератора случайных чисел на основе движений глаз криптографически стойким, он должен удовлетворять следующим критериям:

\textbf{1. Прохождение IID тестов:}
\begin{itemize}
    \item Хи-квадрат тест: p-value > 0.001
    \item Тест на самую длинную повторяющуюся подстроку: пройден
    \item Все permutation tests: пройдены
    \item Отсутствие значимых автокорреляций
\end{itemize}

\textbf{2. Высокое значение min(H\_original, 8 × H\_bitstring):}
\begin{itemize}
    \item Для криптографических приложений: $H_{min} > 7.0$ бит/байт
    \item Для генерации ключей: $H_{min} \geq 6.5$ бит/байт
    \item Минимально допустимое: $H_{min} > 5.0$ бит/байт
\end{itemize}

\textbf{3. Устойчивость к non-IID атакам:}
\begin{itemize}
    \item Most Common Value Test: самый частый символ не должен встречаться значительно чаще ожидаемого
    \item Collision Test: не должно быть чрезмерного количества совпадений
    \item Markov Test: не должно быть значимых переходных вероятностей
    \item Все оценки энтропии в ea\_non\_iid должны давать схожие результаты
\end{itemize}

\newpage
\section{ЭКСПЕРИМЕНТАЛЬНЫЕ РЕЗУЛЬТАТЫ И ИХ АНАЛИЗ}

\subsection{Результаты тестирования}

Результаты тестов для каждого сценария сведены в таблицу 4.1.

\begin{table}[h]
\centering
\caption{Сводные результаты тестирования энтропии}
\label{tab:test_results_summary}
\begin{tabular}{|p{4cm}|c|c|c|}
\hline
\textbf{Параметр} & \textbf{Серфинг} & \textbf{Случайные движения} & \textbf{Фильм} \\ \hline
Объём данных (движения) & 532 & 1130 & 330 \\ \hline
Объём данных (байты) & 1929 & 3457 & 1601 \\ \hline
H\_original (IID) & 6.388737 & 6.643665 & 6.080165 \\ \hline
H\_bitstring (IID) & 0.965584 & 0.947404 & 0.918429 \\ \hline
min(H\_original, 8×H\_bitstring) (IID) & 6.388737 & 6.643665 & 6.080165 \\ \hline
H\_original (non-IID) & 6.388737 & 6.643665 & 5.775921 \\ \hline
H\_bitstring (non-IID) & 0.664687 & 0.699500 & 0.705646 \\ \hline
min(H\_original, 8×H\_bitstring) (non-IID) & 5.317494 & 5.596000 & 5.645168 \\ \hline
Хи-квадрат тест & Пройден & Не пройден & Пройден \\ \hline
Тест на самую длинную подстроку & Пройден & Пройден & Пройден \\ \hline
Permutation tests & Пройдены & Пройдены & Пройдены \\ \hline
\end{tabular}
\end{table}

\subsection{Анализ результатов по сценариям}

\subsubsection{Серфинг в интернете}

\textbf{Ключевые результаты:}
\begin{itemize}
    \item H\_original (IID): 6.388737 бит/байт
    \item Консервативная оценка (non-IID): 5.317494 бит/байт
    \item Все IID тесты пройдены
\end{itemize}

\textbf{Анализ:} Значение H\_original = 6.388737 бит/байт указывает на высокое качество энтропии (79.86\% от теоретического максимума). Факт прохождения всех IID тестов свидетельствует о том, что данные обладают свойствами независимости и одинакового распределения. Консервативная оценка 5.317494 бит/байт учитывает возможные зависимости между битами и всё равно показывает хороший результат.

\subsubsection{Случайные движения глазами}

\textbf{Ключевые результаты:}
\begin{itemize}
    \item H\_original (IID): 6.643665 бит/байт (наивысшее значение)
    \item Консервативная оценка (non-IID): 5.596000 бит/байт
    \item Хи-квадрат тест не пройден
\end{itemize}

\textbf{Анализ:} Сценарий показывает наивысшее значение H\_original = 6.643665 бит/байт (83.05\% от максимума), что объясняется большей вариативностью сознательных движений. Однако неудача в хи-квадрат тесте указывает на отклонение от равномерного распределения байтов, вероятно вызванное сознательным контролем движений и психологическими факторами.

\subsubsection{Просмотр фильма}

\textbf{Ключевые результаты:}
\begin{itemize}
    \item H\_original (IID): 6.080165 бит/байт
    \item Консервативная оценка (non-IID): 5.645168 бит/байт
    \item Все IID тесты пройдены
\end{itemize}

\textbf{Анализ:} Значение H\_original = 6.080165 бит/байт (76\% от максимума) является самым низким среди трёх сценариев, что объясняется более предсказуемыми паттернами движений при просмотре контента. Однако все IID тесты пройдены, что указывает на хорошие статистические свойства. Интересно, что non-IID оценка (5.645) оказалась выше, чем в сценарии серфинга.
\newpage
\subsection{Сравнительный анализ}

\begin{table}[h]
\centering
\caption{Практическая пригодность различных сценариев}
\label{tab:practical_applicability}
\begin{tabular}{|p{4.5cm}|c|c|c|}
\hline
\textbf{Критерий} & \textbf{Серфинг} & \textbf{Случайные движения} & \textbf{Фильм} \\ \hline
Криптографические ключи (1-10) & 8 & 9 & 6 \\ \hline
Инициализация ГСЧ (1-10) & 10 & 7 & 9 \\ \hline
Дополнительная энтропия (1-10) & 9 & 10 & 8 \\ \hline
Простота использования (1-10) & 10 & 4 & 9 \\ \hline
Воспроизводимость (1-10) & 5 & 3 & 10 \\ \hline
\textbf{Суммарный балл} & \textbf{42} & \textbf{33} & \textbf{42} \\ \hline
\end{tabular}
\end{table}

\textbf{Рекомендации по использованию:}
\begin{enumerate}
    \item \textbf{Для критических криптографических приложений:} Использовать сценарий серфинга в интернете с обязательным криптографическим хешированием выхода.
    \item \textbf{Для генерации сессионных ключей:} Комбинировать энтропию из разных сценариев.
    \item \textbf{Для инициализации PRNG:} Использовать любой из сценариев, так как даже минимальная оценка 5.317 бит/байт обеспечивает достаточную энтропию.
    \item \textbf{Для массового применения:} Рекомендовать сценарий просмотра контента как наиболее естественный для пользователя.
\end{enumerate}
\newpage
\subsection{Ограничения и перспективы}

\textbf{Ограничения исследования:}
\begin{enumerate}
    \item Объём данных: 1320-1680 байт вместо рекомендуемых NIST 1 000 000 семплов
    \item Аппаратные ограничения: Обычная веб-камера вместо специализированного айтрекера
    \item Временные рамки: 10-15 минут на каждый эксперимент
\end{enumerate}

\textbf{Перспективные направления:}
\begin{enumerate}
    \item Комбинирование сценариев для увеличения энтропии
    \item Долгосрочные исследования с большими объёмами данных
    \item Улучшение алгоритмов с адаптивным квантованием
    \item Сравнение с другими биометрическими источниками
    \item Мобильная реализация для смартфонов и планшетов
\end{enumerate}

\newpage
\section*{ЗАКЛЮЧЕНИЕ}
\addcontentsline{toc}{section}{ЗАКЛЮЧЕНИЕ}

В ходе выполнения данной курсовой работы была исследована возможность создания биологического генератора случайных чисел на основе поведенческого фактора --- движений глаз человека. Работа включала теоретическое исследование, разработку программного комплекса, экспериментальную оценку качества энтропии и анализ полученных результатов.

\textbf{Основные достижения работы:}

1. \textbf{Разработан программный комплекс} для сбора энтропии движений глаз, включающий:
   \begin{itemize}
       \item Модуль трекинга взгляда на основе MediaPipe Face Mesh с точностью локализации 468 лицевых ориентиров
       \item Алгоритм детекции значимых движений с пороговой фильтрацией (15 пикселей, 0.05 с)
       \item Систему извлечения энтропии из 6 независимых источников
       \item Интерактивный интерфейс управления с возможностью генерации ключей
   \end{itemize}

2. \textbf{Создан экспериментальный стенд} для оценки качества энтропии в трёх сценариях активности.

3. \textbf{Проведена комплексная оценка качества энтропии} с использованием стандарта NIST SP 800-90B:
   \begin{itemize}
       \item Для сценария серфинга: H\_original = 6.389 бит/байт, все IID тесты пройдены
       \item Для случайных движений: максимальная энтропия 6.644 бит/байт
       \item Для просмотра фильма: H\_original = 6.080 бит/байт, все IID тесты пройдены
   \end{itemize}

\textbf{Ключевые научные и практические результаты:}

1. \textbf{Доказана принципиальная возможность} использования движений глаз в качестве источника энтропии для криптографии.

2. \textbf{Установлено влияние типа активности} на качество энтропии:
   \begin{itemize}
       \item Случайные движения дают максимальное количество энтропии
       \item Серфинг в интернете обеспечивает оптимальный баланс
       \item Просмотр фильма даёт стабильную, хотя и менее обильную энтропию
   \end{itemize}

3. \textbf{Определены практические рекомендации} по использованию технологии.

\textbf{Теоретическая значимость работы:}
\begin{itemize}
    \item Расширены представления о биометрических источниках энтропии
    \item Исследовано влияние когнитивных процессов на качество энтропии
    \item Разработана классификация сценариев использования движений глаз
\end{itemize}

\textbf{Практическая ценность работы:}
\begin{itemize}
    \item Создан работающий прототип биологического ГСЧ
    \item Определены оптимальные параметры сбора данных
    \item Установлены временные рамки генерации ключей
    \item Разработана система оценки качества энтропии
\end{itemize}

\textbf{Общий вывод:}

Разработанный биологический генератор случайных чисел на основе движений глаз демонстрирует высокий потенциал для практического применения в криптографии. Технология обеспечивает доступность, безопасность, удобство и эффективность. Наиболее перспективным для практической реализации признан сценарий серфинга в интернете, который сочетает высокое качество энтропии, отличные статистические свойства и естественность для пользователя.

Проведённое исследование подтверждает, что движения глаз являются перспективным источником энтропии, способным конкурировать с традиционными физическими генераторами случайных чисел. Дальнейшее развитие технологии позволит создать конкурентоспособный биологический ГСЧ для массового использования в системах защиты информации.

\newpage
\section*{СПИСОК ИСПОЛЬЗОВАННОЙ ЛИТЕРАТУРЫ}
\addcontentsline{toc}{section}{СПИСОК ИСПОЛЬЗОВАННОЙ ЛИТЕРАТУРЫ}

\begingroup
\raggedright % Выравнивание по левому краю
\begin{enumerate}
    \item Агиевич, С. В. Криптографические методы / С. В. Агиевич // НИИ прикладных проблем математики и информатики БГУ. — URL: https://apmi.bsu.by/assets/files/agievich/cm.pdf (дата обращения: 12.11.2025).
    
    \item NIST Special Publication 800-90B. Recommendation for the Entropy Sources Used for Random Bit Generation // National Institute of Standards and Technology. — URL: https://csrc.nist.gov/publications/detail/sp/800-90b/final (дата обращения: 16.10.2025).
    
    \item Lugaresi, C. MediaPipe: A Framework for Building Perception Pipelines / C. Lugaresi, J. Tang, H. Nash [et al.] // arXiv. — URL: https://arxiv.org/abs/1906.08172 (дата обращения: 07.12.2025).
    
    \item Ямпольский, В. В. Биометрические методы и средства идентификации личности / В. В. Ямпольский, Д. В. Михеев. — М.: Горячая линия–Телеком, 2011. — 312 с.
\end{enumerate}
\endgroup

\newpage
\section*{ПРИЛОЖЕНИЕ А}
\addcontentsline{toc}{section}{ПРИЛОЖЕНИЕ А}
\noindent\textbf{Исходный код программы}

\begin{lstlisting}[language=Python, caption={Файл: main.py (основной модуль)}]
"""
Основной модуль программы для сбора энтропии движений глаз
Биологический генератор случайных чисел
"""

import cv2
import numpy as np
import math
import time
import json
from collections import deque
from typing import List, Tuple, Optional
import mediapipe as mp

class AdvancedGazeTracker:
    """Класс для трекинга взгляда и анализа движений глаз"""
    
    def __init__(self, screen_width: int = 1920, screen_height: int = 1080):
        self.screen_width = screen_width
        self.screen_height = screen_height
        
        # Инициализация MediaPipe Face Mesh
        self.mp_face_mesh = mp.solutions.face_mesh
        self.face_mesh = self.mp_face_mesh.FaceMesh(
            max_num_faces=1,
            refine_landmarks=True,
            min_detection_confidence=0.8,
            min_tracking_confidence=0.8,
            static_image_mode=False
        )
        
        # Индексы ключевых точек глаз
        self.LEFT_EYE_INDICES = [33, 7, 163, 144, 145, 153, 154, 155, 133, 
                                 173, 157, 158, 159, 160, 161, 246]
        self.RIGHT_EYE_INDICES = [362, 382, 381, 380, 374, 373, 390, 249, 
                                  263, 466, 388, 387, 386, 385, 384, 398]
        
        # Параметры системы
        self.movement_threshold = 15  # пикселей
        self.min_movement_interval = 0.05  # секунд
        self.eye_openness_threshold = 0.4
        
        # Хранение данных
        self.movement_events = deque(maxlen=1000)
        self.gaze_history = deque(maxlen=100)
        self.eye_state_history = deque(maxlen=50)
        
        # Счетчики
        self.frame_count = 0
        self.last_movement_time = 0
        self.consecutive_still_frames = 0
        self.last_valid_gaze = None
        
        print("Инициализация трекера взгляда завершена")
    
    def process_frame(self, frame):
        """Обработка одного кадра"""
        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        results = self.face_mesh.process(rgb_frame)
        
        movement_detected = False
        gaze_data = None
        
        if results.multi_face_landmarks:
            for face_landmarks in results.multi_face_landmarks:
                # Анализ состояния глаз
                eye_state = self._analyze_eye_state(face_landmarks)
                self.eye_state_history.append(eye_state)
                
                # Проверка открытости глаз
                if not eye_state['eyes_open']:
                    self._draw_status(frame, "ГЛАЗА ЗАКРЫТЫ", (0, 0, 255))
                    return frame, None
                
                # Вычисление направления взгляда
                current_gaze = self._calculate_gaze_position(face_landmarks, frame.shape)
                
                # Детекция движения
                movement_detected, movement_info = self._detect_movement(current_gaze)
                
                if movement_detected:
                    # Формирование данных о движении
                    gaze_data = {
                        'x': float(current_gaze[0]),
                        'y': float(current_gaze[1]),
                        'timestamp': time.time(),
                        'movement_magnitude': movement_info['magnitude'],
                        'movement_direction': movement_info['direction'],
                        'eye_openness': eye_state['avg_openness'],
                        'attention_score': self._calculate_attention_score(eye_state)
                    }
                    
                    self.movement_events.append(gaze_data)
                    self.last_movement_time = time.time()
                    self.consecutive_still_frames = 0
                    self.last_valid_gaze = current_gaze
                else:
                    self.consecutive_still_frames += 1
                
                # Визуализация
                self._draw_visualization(frame, face_landmarks, movement_detected, current_gaze)
                status = "ДВИЖЕНИЕ" if movement_detected else f"ПОКОЙ ({self.consecutive_still_frames})"
                color = (0, 255, 0) if movement_detected else (0, 165, 255)
                self._draw_status(frame, status, color)
        
        self.frame_count += 1
        return frame, gaze_data
    
    def _analyze_eye_state(self, landmarks):
        """Анализ состояния глаз"""
        left_openness = self._calculate_eye_openness(landmarks, 'left')
        right_openness = self._calculate_eye_openness(landmarks, 'right')
        
        eyes_open = (left_openness > self.eye_openness_threshold and 
                    right_openness > self.eye_openness_threshold and
                    abs(left_openness - right_openness) < 0.15)
        
        return {
            'eyes_open': eyes_open,
            'left_openness': left_openness,
            'right_openness': right_openness,
            'avg_openness': (left_openness + right_openness) / 2,
            'symmetry': 1.0 - abs(left_openness - right_openness)
        }
    
    def _calculate_eye_openness(self, landmarks, eye):
        """Расчет открытости глаза"""
        if eye == 'left':
            vertical_points = [159, 145]
            horizontal_points = [33, 133]
        else:
            vertical_points = [386, 374]
            horizontal_points = [362, 263]
        
        try:
            # Вертикальное расстояние
            top = landmarks.landmark[vertical_points[0]]
            bottom = landmarks.landmark[vertical_points[1]]
            vertical_dist = abs(top.y - bottom.y)
            
            # Горизонтальное расстояние
            left = landmarks.landmark[horizontal_points[0]]
            right = landmarks.landmark[horizontal_points[1]]
            horizontal_dist = abs(left.x - right.x)
            
            if horizontal_dist == 0:
                return 0.0
            
            openness = min(1.0, (vertical_dist / horizontal_dist) * 2.0)
            return openness
        except:
            return 0.0
    
    def _calculate_gaze_position(self, landmarks, frame_shape):
        """Вычисление позиции взгляда"""
        h, w = frame_shape[:2]
        
        # Центры глаз
        left_center = self._calculate_eye_center(landmarks, self.LEFT_EYE_INDICES)
        right_center = self._calculate_eye_center(landmarks, self.RIGHT_EYE_INDICES)
        
        # Средняя точка между глазами
        gaze_x = (left_center[0] + right_center[0]) / 2
        gaze_y = (left_center[1] + right_center[1]) / 2
        
        # Конвертация в координаты экрана
        screen_x = gaze_x * self.screen_width
        screen_y = gaze_y * self.screen_height
        
        return (screen_x, screen_y)
    
    def _calculate_eye_center(self, landmarks, indices):
        """Вычисление центра глаза"""
        points = []
        for idx in indices:
            point = landmarks.landmark[idx]
            points.append((point.x, point.y))
        
        x_coords = [p[0] for p in points]
        y_coords = [p[1] for p in points]
        
        center_x = sum(x_coords) / len(x_coords)
        center_y = sum(y_coords) / len(y_coords)
        
        return (center_x, center_y)
    
    def _detect_movement(self, current_gaze):
        """Детекция значимого движения"""
        current_time = time.time()
        
        # Проверка временного интервала
        if current_time - self.last_movement_time < self.min_movement_interval:
            return False, {}
        
        if self.last_valid_gaze is None:
            self.last_valid_gaze = current_gaze
            self.gaze_history.append(current_gaze)
            return True, {'magnitude': 0, 'direction': 0}
        
        # Вычисление величины движения
        dx = current_gaze[0] - self.last_valid_gaze[0]
        dy = current_gaze[1] - self.last_valid_gaze[1]
        magnitude = math.sqrt(dx**2 + dy**2)
        
        # Вычисление направления
        direction = math.atan2(dy, dx)
        
        # Проверка порога
        if magnitude > self.movement_threshold:
            self.gaze_history.append(current_gaze)
            return True, {
                'magnitude': magnitude,
                'direction': direction
            }
        
        return False, {}
    
    def _calculate_attention_score(self, eye_state):
        """Расчет уровня внимания"""
        openness_score = eye_state['avg_openness']
        symmetry_score = eye_state['symmetry']
        stability_score = 1.0 - min(1.0, self.consecutive_still_frames / 50.0)
        
        attention = (openness_score * 0.4 + 
                    symmetry_score * 0.3 + 
                    stability_score * 0.3)
        
        return min(1.0, max(0.0, attention))
    
    def _draw_visualization(self, frame, landmarks, movement_detected, gaze_pos):
        """Визуализация результатов"""
        h, w = frame.shape[:2]
        
        # Цвет в зависимости от состояния
        color = (0, 255, 0) if movement_detected else (0, 165, 255)
        
        # Отрисовка ключевых точек глаз
        all_eye_indices = self.LEFT_EYE_INDICES + self.RIGHT_EYE_INDICES
        for idx in all_eye_indices:
            point = landmarks.landmark[idx]
            x = int(point.x * w)
            y = int(point.y * h)
            cv2.circle(frame, (x, y), 2, color, -1)
        
        # Отрисовка точки взгляда
        gaze_x = int(gaze_pos[0] * w / self.screen_width)
        gaze_y = int(gaze_pos[1] * h / self.screen_height)
        
        if movement_detected:
            cv2.circle(frame, (gaze_x, gaze_y), 10, (0, 0, 255), -1)
            cv2.circle(frame, (gaze_x, gaze_y), 15, (255, 255, 255), 2)
        else:
            cv2.circle(frame, (gaze_x, gaze_y), 6, (0, 165, 255), -1)
        
        # Линия к центру экрана
        center_x, center_y = w // 2, h // 2
        cv2.line(frame, (center_x, center_y), (gaze_x, gaze_y), color, 1)
    
    def _draw_status(self, frame, text, color):
        """Отображение статуса"""
        stats = self.get_statistics()
        
        info_lines = [
            f"Статус: {text}",
            f"Движений: {stats['movement_count']}",
            f"Статичных кадров: {self.consecutive_still_frames}",
            f"Качество данных: {stats['data_quality']:.1f}%"
        ]
        
        for i, line in enumerate(info_lines):
            y = 30 + i * 25
            cv2.putText(frame, line, (10, y), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 3)
            cv2.putText(frame, line, (10, y), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 1)
    
    def get_statistics(self):
        """Получение статистики"""
        movement_count = len(self.movement_events)
        total_frames = self.frame_count
        
        if total_frames == 0:
            return {
                'movement_count': 0,
                'movement_rate': 0.0,
                'data_quality': 0.0,
                'avg_magnitude': 0.0
            }
        
        # Средняя величина движения
        magnitudes = [e['movement_magnitude'] for e in self.movement_events 
                     if 'movement_magnitude' in e]
        avg_magnitude = np.mean(magnitudes) if magnitudes else 0.0
        
        # Качество данных (процент кадров с открытыми глазами)
        valid_eye_states = [s for s in self.eye_state_history if s['eyes_open']]
        data_quality = (len(valid_eye_states) / len(self.eye_state_history)) * 100 \
                      if self.eye_state_history else 0.0
        
        return {
            'movement_count': movement_count,
            'movement_rate': (movement_count / total_frames) * 100,
            'data_quality': data_quality,
            'avg_magnitude': avg_magnitude,
            'total_frames': total_frames
        }


class EntropyGenerator:
    """Генератор энтропии на основе движений глаз"""
    
    def __init__(self, gaze_tracker):
        self.tracker = gaze_tracker
        self.entropy_pool = deque(maxlen=1000)
        self.bit_counter = 0
        
    def extract_entropy_bits(self):
        """Извлечение битов энтропии из движений"""
        if len(self.tracker.movement_events) < 5:
            return []
        
        bits = []
        recent_movements = list(self.tracker.movement_events)[-10:]
        
        for movement in recent_movements:
            # Извлечение битов из координат
            x_bits = self._extract_bits_from_float(movement['x'], 4)
            y_bits = self._extract_bits_from_float(movement['y'], 4)
            
            # Извлечение битов из величины движения
            mag_bits = self._extract_bits_from_float(movement['movement_magnitude'], 4)
            
            # Извлечение битов из направления
            dir_bits = self._extract_bits_from_direction(movement['movement_direction'])
            
            # Извлечение битов из временной метки
            time_bits = self._extract_bits_from_timestamp(movement['timestamp'])
            
            # Извлечение битов из физиологических параметров
            phys_bits = self._extract_physiological_bits(movement)
            
            # Объединение всех битов
            movement_bits = x_bits + y_bits + mag_bits + dir_bits + time_bits + phys_bits
            bits.extend(movement_bits)
            
            # Добавление в пул энтропии
            self._add_to_entropy_pool(movement_bits)
        
        self.bit_counter += len(bits)
        return bits
    
    def _extract_bits_from_float(self, value: float, num_bits: int) -> List[int]:
        """Извлечение битов из числа с плавающей запятой"""
        # Масштабирование и преобразование в целое число
        int_value = int(abs(value) * 1000) % (1 << (num_bits * 2))
        # Извлечение младших битов
        bits = []
        for i in range(num_bits):
            bits.append((int_value >> i) & 1)
        return bits
    
    def _extract_bits_from_direction(self, direction: float) -> List[int]:
        """Извлечение битов из направления движения"""
        # Квантование направления в 8 секторов
        sector = int((direction + math.pi) / (2 * math.pi) * 8) % 8
        # Преобразование в 3 бита
        bits = [(sector >> i) & 1 for i in range(3)]
        return bits
    
    def _extract_bits_from_timestamp(self, timestamp: float) -> List[int]:
        """Извлечение битов из временной метки"""
        # Извлечение микросекундной части
        microseconds = int((timestamp - int(timestamp)) * 1e6)
        # Извлечение 4 младших битов
        bits = [(microseconds >> i) & 1 for i in range(4)]
        return bits
    
    def _extract_physiological_bits(self, movement: dict) -> List[int]:
        """Извлечение битов из физиологических параметров"""
        bits = []
        
        # Открытость глаз (3 бита)
        openness_int = int(movement['eye_openness'] * 100) % 8
        bits.extend([(openness_int >> i) & 1 for i in range(3)])
        
        # Уровень внимания (3 бита)
        attention_int = int(movement['attention_score'] * 100) % 8
        bits.extend([(attention_int >> i) & 1 for i in range(3)])
        
        return bits
    
    def _add_to_entropy_pool(self, bits: List[int]):
        """Добавление битов в пул энтропии"""
        # Преобразование битов в байты
        for i in range(0, len(bits), 8):
            byte_bits = bits[i:i+8]
            if len(byte_bits) == 8:
                byte_value = 0
                for j, bit in enumerate(byte_bits):
                    byte_value |= (bit << j)
                self.entropy_pool.append(byte_value)
    
    def generate_random_key(self, key_size_bits: int = 256) -> Optional[bytes]:
        """Генерация криптографического ключа"""
        if len(self.tracker.movement_events) < 20:
            print(f"Недостаточно движений: {len(self.tracker.movement_events)}/20")
            return None
        
        print(f"Генерация ключа {key_size_bits} бит...")
        
        # Сбор энтропии
        all_bits = []
        while len(all_bits) < key_size_bits:
            new_bits = self.extract_entropy_bits()
            if new_bits:
                all_bits.extend(new_bits)
            else:
                time.sleep(0.1)
        
        # Обрезка до нужного размера
        key_bits = all_bits[:key_size_bits]
        
        # Преобразование в байты
        key_bytes = bytearray()
        for i in range(0, len(key_bits), 8):
            byte_bits = key_bits[i:i+8]
            if len(byte_bits) == 8:
                byte_value = 0
                for j, bit in enumerate(byte_bits):
                    byte_value |= (bit << j)
                key_bytes.append(byte_value)
        
        # Проверка баланса
        ones = sum(key_bits)
        proportion = ones / len(key_bits)
        print(f"Сгенерирован ключ {len(key_bytes)} байт")
        print(f"Баланс битов: {proportion:.3f} (идеально 0.5)")
        
        return bytes(key_bytes)


def main():
    """Основная функция программы"""
    print("=" * 60)
    print("БИОЛОГИЧЕСКИЙ ГЕНЕРАТОР СЛУЧАЙНЫХ ЧИСЕЛ")
    print("На основе анализа движений глаз")
    print("=" * 60)
    
    # Инициализация трекера
    tracker = AdvancedGazeTracker()
    entropy_gen = EntropyGenerator(tracker)
    
    # Открытие видеопотока
    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        print("Ошибка: не удалось открыть камеру")
        return
    
    print("\nУправление:")
    print("  S - Статистика")
    print("  B - Генерация 128 бит")
    print("  K - Генерация 256-битного ключа")
    print("  R - Сброс данных")
    print("  Q/ESC - Выход")
    print("\nНачните движения глазами...")
    
    try:
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            # Обработка кадра
            processed_frame, movement_data = tracker.process_frame(frame)
            
            # Отображение результата
            cv2.imshow('Eye Tracker - BioRNG', processed_frame)
            
            # Обработка клавиш
            key = cv2.waitKey(1) & 0xFF
            
            if key == ord('q') or key == 27:  # Q или ESC
                print("\nЗавершение работы...")
                break
                
            elif key == ord('s'):  # Статистика
                stats = tracker.get_statistics()
                print(f"\nСтатистика:")
                print(f"  Обработано кадров: {stats['total_frames']}")
                print(f"  Зарегистрировано движений: {stats['movement_count']}")
                print(f"  Процент движения: {stats['movement_rate']:.1f}%")
                print(f"  Качество данных: {stats['data_quality']:.1f}%")
                print(f"  Средняя величина движения: {stats['avg_magnitude']:.1f} пикс.")
                
            elif key == ord('b'):  # Генерация 128 бит
                print("\nГенерация 128 случайных битов...")
                bits = []
                attempts = 0
                while len(bits) < 128 and attempts < 100:
                    new_bits = entropy_gen.extract_entropy_bits()
                    if new_bits:
                        bits.extend(new_bits)
                    attempts += 1
                    time.sleep(0.05)
                
                if len(bits) >= 128:
                    # Сохранение в файл
                    with open("random_bits.txt", "w") as f:
                        f.write(''.join(str(bit) for bit in bits[:128]))
                    
                    ones = sum(bits[:128])
                    proportion = ones / 128
                    print(f"Сгенерировано 128 битов")
                    print(f"Баланс: {proportion:.3f} (0/1: {ones}/{128-ones})")
                    print(f"Сохранено в random_bits.txt")
                else:
                    print(f"Не удалось собрать достаточно энтропии")
                    
            elif key == ord('k'):  # Генерация ключа
                key_bytes = entropy_gen.generate_random_key(256)
                if key_bytes:
                    # Сохранение ключа
                    with open("crypto_key.bin", "wb") as f:
                        f.write(key_bytes)
                    
                    # Вывод HEX представления
                    hex_key = key_bytes.hex()[:64]  # Первые 32 байта
                    print(f"Ключ (HEX, первые 32 байта): {hex_key}")
                    print(f"Полный ключ сохранен в crypto_key.bin")
                    
            elif key == ord('r'):  # Сброс
                tracker.movement_events.clear()
                tracker.gaze_history.clear()
                tracker.eye_state_history.clear()
                tracker.consecutive_still_frames = 0
                print("\nДанные сброшены")
    
    except KeyboardInterrupt:
        print("\nПрервано пользователем")
    
    finally:
        # Освобождение ресурсов
        cap.release()
        cv2.destroyAllWindows()
        
        # Финальная статистика
        stats = tracker.get_statistics()
        print(f"\nИтоговая статистика:")
        print(f"  Всего кадров: {stats['total_frames']}")
        print(f"  Всего движений: {stats['movement_count']}")
        print(f"  Собрано битов энтропии: {entropy_gen.bit_counter}")


if __name__ == "__main__":
    main()
\end{lstlisting}

\end{document}